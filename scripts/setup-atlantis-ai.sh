#!/usr/bin/env bash
set -euo pipefail

# StackKit Atlantis AI Reviewer ì›í´ë¦­ ì…‹ì—… ìŠ¤í¬ë¦½íŠ¸
# ì‚¬ìš©ë²•: ./setup-atlantis-ai.sh --github-token=ghp_xxx --slack-webhook=https://... --openai-key=sk-xxx

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"

# ê¸°ë³¸ê°’ ì„¤ì •
STACK_NAME="atlantis-ai-reviewer"
ENVIRONMENT="dev"
REGION="ap-northeast-2"
GITHUB_TOKEN=""
SLACK_WEBHOOK=""
OPENAI_API_KEY=""
INFRACOST_API_KEY=""
WEBHOOK_SECRET=""
REPO_ALLOWLIST=""
GIT_USERNAME=""
S3_BUCKET=""
DYNAMODB_TABLE=""
AUTO_DETECT=false
EXISTING_VPC_ID=""
EXISTING_ALB_NAME=""
SKIP_BUILD=false
SKIP_DEPLOY=false
DRY_RUN=false

show_usage() {
    cat << 'EOF'
ğŸš€ StackKit Atlantis AI Reviewer ì›í´ë¦­ ì…‹ì—…

ì‚¬ìš©ë²•:
    ./setup-atlantis-ai.sh [OPTIONS]

í•„ìˆ˜ ì˜µì…˜:
    --github-token=TOKEN        GitHub Personal Access Token (repo, admin:repo_hook ê¶Œí•œ í•„ìš”)
    --slack-webhook=URL         Slack Webhook URL
    --openai-key=KEY           OpenAI API Key
    --infracost-key=KEY        Infracost API Key (ì •í™•í•œ ë¹„ìš© ì¶”ì •ìš©)

ì„ íƒ ì˜µì…˜:
    --s3-bucket=BUCKET         Terraform ìƒíƒœ ì €ì¥ìš© S3 ë²„í‚· (ê¸°ë³¸: stackkit-tfstate)
    --dynamodb-table=TABLE     Terraform ì ê¸ˆìš© DynamoDB í…Œì´ë¸” (ê¸°ë³¸: í™˜ê²½-stackkit-tf-lock)
    --stack-name=NAME          ìŠ¤íƒ ì´ë¦„ (ê¸°ë³¸: atlantis-ai-reviewer)
    --environment=ENV          í™˜ê²½ (ê¸°ë³¸: dev)
    --auto-detect              ê¸°ì¡´ AWS ë¦¬ì†ŒìŠ¤ ìë™ ê°ì§€ ë° ì¬ì‚¬ìš©
    --vpc-id=VPC_ID           ì‚¬ìš©í•  ê¸°ì¡´ VPC ID (ìë™ ê°ì§€ ë¬´ì‹œ)
    --alb-name=ALB_NAME       ì‚¬ìš©í•  ê¸°ì¡´ ALB ì´ë¦„ (ìë™ ê°ì§€ ë¬´ì‹œ)
    --region=REGION            AWS ë¦¬ì „ (ê¸°ë³¸: us-east-1)
    --webhook-secret=SECRET    GitHub Webhook Secret (ìë™ ìƒì„±ë¨)
    --repo-allowlist=LIST      í—ˆìš©í•  Repository íŒ¨í„´ (ì˜ˆ: github.com/myorg/*)
    --git-username=USER        Git ì‚¬ìš©ìëª…
    --skip-build              AI Reviewer ë¹Œë“œ ê±´ë„ˆë›°ê¸°
    --skip-deploy             Terraform ë°°í¬ ê±´ë„ˆë›°ê¸°
    --dry-run                 ì‹¤ì œ ì‹¤í–‰ ì—†ì´ ê³„íšë§Œ ì¶œë ¥

ì˜ˆì‹œ:
    ./setup-atlantis-ai.sh \
        --github-token=ghp_xxxxxxxxxxxx \
        --slack-webhook=https://hooks.slack.com/services/T00/B00/xxx \
        --openai-key=sk-xxxxxxxxxxxxxxxx \
        --infracost-key=ico-xxxxxxxxxxxxxxxx \
        --s3-bucket=connectly-prod \
        --dynamodb-table=dev-connectly-tf-lock \
        --repo-allowlist="github.com/myorg/*" \
        --git-username=myusername

GitHub Token ê¶Œí•œ:
    - repo (ì „ì²´ ì €ì¥ì†Œ ì ‘ê·¼)
    - admin:repo_hook (ì›¹í›… ê´€ë¦¬)

EOF
}

# ì¸ìˆ˜ íŒŒì‹±
while [[ $# -gt 0 ]]; do
    case $1 in
        --github-token=*)
            GITHUB_TOKEN="${1#*=}"
            shift
            ;;
        --slack-webhook=*)
            SLACK_WEBHOOK="${1#*=}"
            shift
            ;;
        --openai-key=*)
            OPENAI_API_KEY="${1#*=}"
            shift
            ;;
        --infracost-key=*)
            INFRACOST_API_KEY="${1#*=}"
            shift
            ;;
        --stack-name=*)
            STACK_NAME="${1#*=}"
            shift
            ;;
        --environment=*)
            ENVIRONMENT="${1#*=}"
            shift
            ;;
        --region=*)
            REGION="${1#*=}"
            shift
            ;;
        --webhook-secret=*)
            WEBHOOK_SECRET="${1#*=}"
            shift
            ;;
        --repo-allowlist=*)
            REPO_ALLOWLIST="${1#*=}"
            shift
            ;;
        --git-username=*)
            GIT_USERNAME="${1#*=}"
            shift
            ;;
        --s3-bucket=*)
            S3_BUCKET="${1#*=}"
            shift
            ;;
        --dynamodb-table=*)
            DYNAMODB_TABLE="${1#*=}"
            shift
            ;;
        --auto-detect)
            AUTO_DETECT=true
            shift
            ;;
        --vpc-id=*)
            EXISTING_VPC_ID="${1#*=}"
            shift
            ;;
        --alb-name=*)
            EXISTING_ALB_NAME="${1#*=}"
            shift
            ;;
        --skip-build)
            SKIP_BUILD=true
            shift
            ;;
        --skip-deploy)
            SKIP_DEPLOY=true
            shift
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --help|-h)
            show_usage
            exit 0
            ;;
        *)
            echo "âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜µì…˜: $1"
            show_usage
            exit 1
            ;;
    esac
done

# í•„ìˆ˜ ì¸ìˆ˜ ê²€ì¦
if [[ -z "$GITHUB_TOKEN" || -z "$SLACK_WEBHOOK" || -z "$OPENAI_API_KEY" ]]; then
    echo "âŒ í•„ìˆ˜ ì¸ìˆ˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
    show_usage
    exit 1
fi

# Webhook secret ìë™ ìƒì„±
if [[ -z "$WEBHOOK_SECRET" ]]; then
    WEBHOOK_SECRET=$(openssl rand -hex 32)
fi

# ê¸°ë³¸ê°’ ì„¤ì •
if [[ -z "$REPO_ALLOWLIST" ]]; then
    REPO_ALLOWLIST="github.com/*/*"
fi

if [[ -z "$GIT_USERNAME" ]]; then
    GIT_USERNAME=$(git config user.name 2>/dev/null || echo "atlantis")
fi

echo "ğŸš€ StackKit Atlantis AI Reviewer ì…‹ì—… ì‹œì‘"
echo "=================================="
echo "ìŠ¤íƒ ì´ë¦„: $STACK_NAME"
echo "í™˜ê²½: $ENVIRONMENT"
echo "ë¦¬ì „: $REGION"
echo "Repository í—ˆìš© íŒ¨í„´: $REPO_ALLOWLIST"
echo "Git ì‚¬ìš©ìëª…: $GIT_USERNAME"
echo "Webhook Secret: ${WEBHOOK_SECRET:0:8}..."
echo ""

if [[ "$DRY_RUN" == "true" ]]; then
    echo "ğŸ” DRY RUN ëª¨ë“œ - ì‹¤ì œ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ"
    echo ""
fi

# ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ìë™ ê°ì§€ í•¨ìˆ˜ë“¤
detect_existing_resources() {
    echo "ğŸ” ê¸°ì¡´ AWS ë¦¬ì†ŒìŠ¤ ìë™ ê°ì§€ ì¤‘..."
    
    # VPC ê°ì§€
    if [[ -z "$EXISTING_VPC_ID" ]]; then
        echo "   VPC ê²€ìƒ‰ ì¤‘..."
        local vpcs=$(aws ec2 describe-vpcs --query 'Vpcs[?State==`available`].[VpcId,CidrBlock,Tags[?Key==`Name`].Value|[0]]' --output table 2>/dev/null)
        if [[ -n "$vpcs" && "$vpcs" != *"None"* ]]; then
            echo "   ğŸ“‹ ë°œê²¬ëœ VPC ëª©ë¡:"
            echo "$vpcs"
            echo ""
            read -p "   ì‚¬ìš©í•  VPC IDë¥¼ ì…ë ¥í•˜ì„¸ìš” (ìƒˆë¡œ ìƒì„±í•˜ë ¤ë©´ Enter): " vpc_choice
            if [[ -n "$vpc_choice" ]]; then
                EXISTING_VPC_ID="$vpc_choice"
                echo "   âœ… VPC $EXISTING_VPC_ID ì„ íƒë¨"
            fi
        fi
    fi
    
    # ì„ íƒëœ VPCì˜ ì„œë¸Œë„· ê°ì§€
    if [[ -n "${EXISTING_VPC_ID}" ]]; then
        echo "   VPC ${EXISTING_VPC_ID}ì˜ ì„œë¸Œë„· ê²€ìƒ‰ ì¤‘..."
        local subnets=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$EXISTING_VPC_ID" --query 'Subnets[].{SubnetId:SubnetId,AZ:AvailabilityZone,CIDR:CidrBlock,Public:MapPublicIpOnLaunch,Name:Tags[?Key==`Name`].Value|[0]}' --output table 2>/dev/null)
        if [[ -n "$subnets" ]]; then
            echo "   ğŸ“‹ VPCì˜ ì„œë¸Œë„· ëª©ë¡:"
            echo "$subnets"
        fi
    fi
    
    # ALB ê°ì§€
    if [[ -z "$EXISTING_ALB_NAME" ]]; then
        echo "   Application Load Balancer ê²€ìƒ‰ ì¤‘..."
        local albs=$(aws elbv2 describe-load-balancers --query 'LoadBalancers[?Type==`application`].[LoadBalancerName,DNSName,VpcId]' --output table 2>/dev/null)
        if [[ -n "$albs" && "$albs" != *"None"* ]]; then
            echo "   ğŸ“‹ ë°œê²¬ëœ ALB ëª©ë¡:"
            echo "$albs"
            echo ""
            read -p "   ì‚¬ìš©í•  ALB ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ìƒˆë¡œ ìƒì„±í•˜ë ¤ë©´ Enter): " alb_choice
            if [[ -n "$alb_choice" ]]; then
                EXISTING_ALB_NAME="$alb_choice"
                echo "   âœ… ALB $EXISTING_ALB_NAME ì„ íƒë¨"
            fi
        fi
    fi
    
    echo ""
}

# ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë³´ ìˆ˜ì§‘
collect_existing_resource_info() {
    if [[ -n "${EXISTING_VPC_ID}" ]]; then
        echo "ğŸ” ê¸°ì¡´ VPC ì •ë³´ ìˆ˜ì§‘ ì¤‘..."
        
        # Public ì„œë¸Œë„· ìˆ˜ì§‘
        EXISTING_PUBLIC_SUBNETS=$(aws ec2 describe-subnets \
            --filters "Name=vpc-id,Values=${EXISTING_VPC_ID}" "Name=map-public-ip-on-launch,Values=true" \
            --query 'Subnets[].SubnetId' --output text 2>/dev/null | tr '\t' ',')
        
        # Private ì„œë¸Œë„· ìˆ˜ì§‘
        EXISTING_PRIVATE_SUBNETS=$(aws ec2 describe-subnets \
            --filters "Name=vpc-id,Values=${EXISTING_VPC_ID}" "Name=map-public-ip-on-launch,Values=false" \
            --query 'Subnets[].SubnetId' --output text 2>/dev/null | tr '\t' ',')
        
        echo "   âœ… Public ì„œë¸Œë„·: ${EXISTING_PUBLIC_SUBNETS}"
        echo "   âœ… Private ì„œë¸Œë„·: ${EXISTING_PRIVATE_SUBNETS}"
    fi
    
    if [[ -n "${EXISTING_ALB_NAME}" ]]; then
        echo "ğŸ” ê¸°ì¡´ ALB ì •ë³´ ìˆ˜ì§‘ ì¤‘..."
        
        # ALB ARN ë° DNS ì´ë¦„ ìˆ˜ì§‘
        EXISTING_ALB_ARN=$(aws elbv2 describe-load-balancers \
            --names "${EXISTING_ALB_NAME}" \
            --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null)
        
        EXISTING_ALB_DNS=$(aws elbv2 describe-load-balancers \
            --names "${EXISTING_ALB_NAME}" \
            --query 'LoadBalancers[0].DNSName' --output text 2>/dev/null)
        
        echo "   âœ… ALB ARN: ${EXISTING_ALB_ARN}"
        echo "   âœ… ALB DNS: ${EXISTING_ALB_DNS}"
    fi
    
    echo ""
}

# ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ê²€ì¦
echo "ğŸ” ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ê²€ì¦ ì¤‘..."

# AWS CLI í™•ì¸
if ! command -v aws &> /dev/null; then
    echo "âŒ AWS CLIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    exit 1
fi

# AWS ìê²©ì¦ëª… í™•ì¸
if [[ "$DRY_RUN" != "true" ]]; then
    if ! aws sts get-caller-identity &> /dev/null; then
        echo "âŒ AWS ìê²©ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        echo "   aws configureë¥¼ ì‹¤í–‰í•˜ì—¬ ì„¤ì •í•˜ì„¸ìš”."
        exit 1
    fi
fi

# Terraform í™•ì¸
if ! command -v terraform &> /dev/null; then
    echo "âŒ Terraformì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    exit 1
fi

# Java í™•ì¸ (AI Reviewer ë¹Œë“œìš©)
if [[ "$SKIP_BUILD" != "true" ]] && ! command -v java &> /dev/null; then
    echo "âŒ Javaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (AI Reviewer ë¹Œë“œ í•„ìš”)"
    exit 1
fi

echo "âœ… ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ê²€ì¦ ì™„ë£Œ"
echo ""

# ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ìë™ ê°ì§€ ì‹¤í–‰
if [[ "$AUTO_DETECT" == "true" ]] || [[ -n "$EXISTING_VPC_ID" ]] || [[ -n "$EXISTING_ALB_NAME" ]]; then
    detect_existing_resources
    collect_existing_resource_info
fi

# Step 1: AI Reviewer ë¹Œë“œ
if [[ "$SKIP_BUILD" != "true" ]]; then
    echo "ğŸ”¨ Step 1: AI Reviewer Lambda ë¹Œë“œ ì¤‘..."
    
    if [[ "$DRY_RUN" != "true" ]]; then
        cd "$PROJECT_ROOT/ai-reviewer"
        ./build.sh
        echo "âœ… AI Reviewer ë¹Œë“œ ì™„ë£Œ"
    else
        echo "   [DRY RUN] cd $PROJECT_ROOT/ai-reviewer && ./build.sh"
    fi
    echo ""
else
    echo "â­ï¸  Step 1: AI Reviewer ë¹Œë“œ ê±´ë„ˆë›°ê¸°"
    echo ""
fi

# Step 2: AWS Secrets Manager ì„¤ì •
echo "ğŸ” Step 2: AWS Secrets Manager ì‹œí¬ë¦¿ ìƒì„± ì¤‘..."

create_secret() {
    local secret_name="$1"
    local secret_value="$2"
    local description="$3"
    
    if [[ "$DRY_RUN" == "true" ]]; then
        echo "   [DRY RUN] aws secretsmanager create-secret --name '$secret_name' --description '$description'"
        return 0
    fi
    
    # ê¸°ì¡´ ì‹œí¬ë¦¿ í™•ì¸
    if aws secretsmanager describe-secret --secret-id "$secret_name" &> /dev/null; then
        echo "   âš ï¸  ì‹œí¬ë¦¿ '$secret_name'ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ì—…ë°ì´íŠ¸ ì¤‘..."
        aws secretsmanager update-secret --secret-id "$secret_name" --secret-string "$secret_value"
    else
        echo "   ğŸ“ ì‹œí¬ë¦¿ '$secret_name' ìƒì„± ì¤‘..."
        aws secretsmanager create-secret \
            --name "$secret_name" \
            --description "$description" \
            --secret-string "$secret_value"
    fi
}

create_secret "atlantis/github-token" "$GITHUB_TOKEN" "GitHub Personal Access Token for Atlantis"
create_secret "atlantis/webhook-secret" "$WEBHOOK_SECRET" "GitHub Webhook Secret for Atlantis"
create_secret "atlantis/slack-webhook" "$SLACK_WEBHOOK" "Slack Webhook URL for AI Review notifications"
create_secret "atlantis/openai-api-key" "$OPENAI_API_KEY" "OpenAI API Key for AI Reviews"

# Infracost API Key (ì„ íƒì‚¬í•­)
if [[ -n "$INFRACOST_API_KEY" ]]; then
    create_secret "atlantis/infracost-api-key" "$INFRACOST_API_KEY" "Infracost API Key for cost estimation"
    echo "   ğŸ’° Infracost API Keyê°€ ì„¤ì •ë˜ì–´ ì •í™•í•œ ë¹„ìš© ì¶”ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
else
    echo "   âš ï¸  Infracost API Keyê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ. ê¸°ë³¸ ë¹„ìš© ì¶”ì •ë§Œ ì œê³µë©ë‹ˆë‹¤."
fi

echo "âœ… AWS Secrets Manager ì„¤ì • ì™„ë£Œ"
echo ""

# ê¸°ë³¸ê°’ ì„¤ì •
if [[ -z "$S3_BUCKET" ]]; then
    S3_BUCKET="stackkit-tfstate"
fi

if [[ -z "$DYNAMODB_TABLE" ]]; then
    DYNAMODB_TABLE="$ENVIRONMENT-stackkit-tf-lock"
fi

# VPC ì„¤ì • ê¸°ë³¸ê°’
USE_EXISTING_VPC="false"
EXISTING_VPC_ID=""
EXISTING_PUBLIC_SUBNET_IDS="[]"
EXISTING_PRIVATE_SUBNET_IDS="[]"

# Step 3: Terraform ìŠ¤íƒ ìƒì„±
STACK_DIR="$PROJECT_ROOT/terraform/stacks/$STACK_NAME/$ENVIRONMENT"

echo "ğŸ—ï¸  Step 3: Terraform ìŠ¤íƒ ìƒì„± ì¤‘..."

if [[ "$DRY_RUN" != "true" ]]; then
    cd "$PROJECT_ROOT/terraform/scripts"
    
    if [[ ! -d "$STACK_DIR" ]]; then
        echo "   ğŸ“ ìƒˆ ìŠ¤íƒ ìƒì„±: $STACK_NAME-$ENVIRONMENT-$REGION"
        # ë°±ì—”ë“œ ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
        BACKEND_FILE="$STACK_DIR/backend.hcl"
        if [[ -f "$BACKEND_FILE" ]]; then
            echo "   ğŸ”§ Backend ì„¤ì • ì—…ë°ì´íŠ¸ ì¤‘..."
            sed -i "s/bucket.*=.*/bucket = \"$S3_BUCKET\"/" "$BACKEND_FILE"
            sed -i "s/dynamodb_table.*=.*/dynamodb_table = \"$DYNAMODB_TABLE\"/" "$BACKEND_FILE"
            sed -i "s/region.*=.*/region = \"$REGION\"/" "$BACKEND_FILE"
        fi
        
        ./new-stack.sh "$STACK_NAME" "$ENVIRONMENT" --template=atlantis-ai-reviewer --region="$REGION" --bucket="$S3_BUCKET" --table="$DYNAMODB_TABLE"
    else
        echo "   âš ï¸  ìŠ¤íƒ ë””ë ‰í† ë¦¬ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: $STACK_DIR"
    fi
else
    echo "   [DRY RUN] Backend ì„¤ì • ì—…ë°ì´íŠ¸: $S3_BUCKET, $DYNAMODB_TABLE"
    echo "   [DRY RUN] ./new-stack.sh $STACK_NAME $ENVIRONMENT --template=atlantis-ai-reviewer --region=$REGION --bucket=$S3_BUCKET --table=$DYNAMODB_TABLE"
fi

echo "âœ… Terraform ìŠ¤íƒ ìƒì„± ì™„ë£Œ"
echo ""

# Step 4: Terraform ë³€ìˆ˜ ì„¤ì •
echo "âš™ï¸  Step 4: Terraform ë³€ìˆ˜ ì„¤ì • ì¤‘..."

TFVARS_FILE="$STACK_DIR/terraform.tfvars"

if [[ "$DRY_RUN" != "true" ]]; then
    # AWS ê³„ì • ID ê°€ì ¸ì˜¤ê¸°
    AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
    
    # terraform.tfvars íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
    if [[ ! -f "$TFVARS_FILE" ]]; then
        echo "   ğŸ“ terraform.tfvars íŒŒì¼ ìƒì„± ì¤‘..."
        cat > "$TFVARS_FILE" << EOF
# StackKit Atlantis AI Reviewer Configuration
# Generated by setup-atlantis-ai.sh at $(date)

# ê¸°ë³¸ ì„¤ì •
stack_name     = "$STACK_NAME"
env            = "$ENVIRONMENT"
region         = "$REGION"
git_username   = "$GIT_USERNAME"
repo_allowlist = "$REPO_ALLOWLIST"

# Git ë° Webhook ì„¤ì •
webhook_secret = "$WEBHOOK_SECRET"
slack_webhook_url = "$SLACK_WEBHOOK"
openai_api_key = "$OPENAI_API_KEY"

# AWS Secrets Manager ARNs (ìë™ ìƒì„±ë¨)
git_token_secret_arn        = "arn:aws:secretsmanager:$REGION:$AWS_ACCOUNT_ID:secret:atlantis/github-token"
aws_access_key_secret_arn   = "arn:aws:secretsmanager:$REGION:$AWS_ACCOUNT_ID:secret:atlantis/aws-access-key"
aws_secret_key_secret_arn   = "arn:aws:secretsmanager:$REGION:$AWS_ACCOUNT_ID:secret:atlantis/aws-secret-key"

# ê¸°ì¡´ VPC ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: false - ìƒˆ VPC ìƒì„±)
use_existing_vpc = false
# existing_vpc_id = "vpc-0123456789abcdef0"
# existing_public_subnet_ids = ["subnet-0123456789abcdef0", "subnet-0abcdef123456789"]
# existing_private_subnet_ids = ["subnet-0fedcba987654321", "subnet-0987654321fedcba"]

# ê¸°ì¡´ S3 ë²„í‚· ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: false - ìƒˆ ë²„í‚· ìƒì„±)
use_existing_s3_bucket = false
# existing_s3_bucket_name = "my-existing-bucket"

# ê¸°ì¡´ ECS í´ëŸ¬ìŠ¤í„° ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: false - ìƒˆ í´ëŸ¬ìŠ¤í„° ìƒì„±)
use_existing_ecs_cluster = false
# existing_ecs_cluster_name = "my-existing-cluster"

# ê¸°ì¡´ ALB ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: false - ìƒˆ ALB ìƒì„±)
use_existing_alb = false
# existing_alb_arn = "arn:aws:elasticloadbalancing:region:account:loadbalancer/app/name/id"
# existing_alb_dns_name = "alb-name-123456789.region.elb.amazonaws.com"
EOF
        
        # Infracost API Key ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if [[ -n "$INFRACOST_API_KEY" ]]; then
            echo "" >> "$TFVARS_FILE"
            echo "# Infracost Configuration" >> "$TFVARS_FILE"
            echo "infracost_api_key = \"$INFRACOST_API_KEY\"" >> "$TFVARS_FILE"
        fi
    fi
    
    
    # ê¸°ì¡´ VPC ì‚¬ìš© ì„¤ì •
    if [[ -n "$EXISTING_VPC_ID" ]]; then
        echo "   ğŸ”„ ê¸°ì¡´ VPC ì‚¬ìš© ì„¤ì •: $EXISTING_VPC_ID"
        sed -i '' "s/use_existing_vpc = false/use_existing_vpc = true/" "$TFVARS_FILE"
        sed -i '' "s/# existing_vpc_id = \"vpc-0123456789abcdef0\"/existing_vpc_id = \"$EXISTING_VPC_ID\"/" "$TFVARS_FILE"
        
        # ì„œë¸Œë„· ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        if [[ -n "$EXISTING_PUBLIC_SUBNETS" ]]; then
            PUBLIC_SUBNET_ARRAY="[\"$(echo "$EXISTING_PUBLIC_SUBNETS" | sed 's/,/", "/g')\"]"
            sed -i '' "s/# existing_public_subnet_ids = \[\"subnet-0123456789abcdef0\", \"subnet-0abcdef123456789\"\]/existing_public_subnet_ids = $PUBLIC_SUBNET_ARRAY/" "$TFVARS_FILE"
        fi
        
        if [[ -n "$EXISTING_PRIVATE_SUBNETS" ]]; then
            PRIVATE_SUBNET_ARRAY="[\"$(echo "$EXISTING_PRIVATE_SUBNETS" | sed 's/,/", "/g')\"]"
            sed -i '' "s/# existing_private_subnet_ids = \[\"subnet-0fedcba987654321\", \"subnet-0987654321fedcba\"\]/existing_private_subnet_ids = $PRIVATE_SUBNET_ARRAY/" "$TFVARS_FILE"
        fi
    fi
    
    # ê¸°ì¡´ ALB ì‚¬ìš© ì„¤ì •
    if [[ -n "$EXISTING_ALB_NAME" ]]; then
        echo "   ğŸ”„ ê¸°ì¡´ ALB ì‚¬ìš© ì„¤ì •: $EXISTING_ALB_NAME"
        sed -i '' "s/use_existing_alb = false/use_existing_alb = true/" "$TFVARS_FILE"
        sed -i '' "s|# existing_alb_arn = \"arn:aws:elasticloadbalancing:region:account:loadbalancer/app/name/id\"|existing_alb_arn = \"$EXISTING_ALB_ARN\"|" "$TFVARS_FILE"
        sed -i '' "s/# existing_alb_dns_name = \"alb-name-123456789.region.elb.amazonaws.com\"/existing_alb_dns_name = \"$EXISTING_ALB_DNS\"/" "$TFVARS_FILE"
    fi

    echo "   ğŸ“ Terraform ë³€ìˆ˜ íŒŒì¼ ì—…ë°ì´íŠ¸: $TFVARS_FILE"
    echo "   ğŸ”‘ AWS ê³„ì • ID: $AWS_ACCOUNT_ID"
    echo "   ğŸ‘¤ Git ì‚¬ìš©ì: $GIT_USERNAME"
    echo "   ğŸ“‹ Repository í—ˆìš© ëª©ë¡: $REPO_ALLOWLIST"
else
    echo "   [DRY RUN] Terraform ë³€ìˆ˜ íŒŒì¼ ìƒì„±: $TFVARS_FILE"
fi

echo "âœ… Terraform ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ"
echo ""

# Step 5: Terraform êµ¬ì„± ê²€ì¦
echo "ğŸ” Step 5: Terraform êµ¬ì„± ê²€ì¦ ì¤‘..."

if [[ "$DRY_RUN" != "true" && -d "$STACK_DIR" ]]; then
    cd "$STACK_DIR"
    
    echo "   ğŸ“‹ Terraform êµ¬ë¬¸ ê²€ì¦ ì¤‘..."
    if ! terraform validate; then
        echo "âŒ Terraform êµ¬ë¬¸ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤."
        echo "   êµ¬ì„±ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
        exit 1
    fi
    
    echo "   ğŸ“Š Terraform ê³„íš ë¯¸ë¦¬ë³´ê¸°..."
    terraform plan -detailed-exitcode -out=tfplan.tmp
    PLAN_EXIT_CODE=$?
    
    if [[ $PLAN_EXIT_CODE -eq 1 ]]; then
        echo "âŒ Terraform ê³„íš ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
        exit 1
    elif [[ $PLAN_EXIT_CODE -eq 2 ]]; then
        echo "   âœ… ì ìš©í•  ë³€ê²½ì‚¬í•­ì´ ê°ì§€ë¨"
        rm -f tfplan.tmp
    else
        echo "   â„¹ï¸  ì ìš©í•  ë³€ê²½ì‚¬í•­ì´ ì—†ìŒ"
        rm -f tfplan.tmp
    fi
    
else
    echo "   [DRY RUN] terraform validate"
    echo "   [DRY RUN] terraform plan -detailed-exitcode"
fi

echo "âœ… Terraform êµ¬ì„± ê²€ì¦ ì™„ë£Œ"
echo ""

# Step 6: Terraform ë°°í¬
if [[ "$SKIP_DEPLOY" != "true" ]]; then
    echo "ğŸš€ Step 6: Terraform ì¸í”„ë¼ ë°°í¬ ì¤‘..."
    
    if [[ "$DRY_RUN" != "true" ]]; then
        cd "$STACK_DIR"
        
        echo "   ğŸ”§ Terraform ì´ˆê¸°í™” ì¤‘..."
        terraform init -backend-config=backend.hcl
        
        echo "   ğŸ“‹ Terraform ê³„íš ìƒì„± ì¤‘..."
        terraform plan -out=tfplan
        
        echo "   ğŸš€ Terraform ë°°í¬ ì‹¤í–‰ ì¤‘..."
        terraform apply tfplan
        
        echo "   ğŸ“Š ë°°í¬ ê²°ê³¼ ì¶œë ¥ ì¤‘..."
        terraform output
        
    else
        echo "   [DRY RUN] cd $STACK_DIR"
        echo "   [DRY RUN] terraform init -backend-config=backend.hcl"
        echo "   [DRY RUN] terraform plan"
        echo "   [DRY RUN] terraform apply"
    fi
    
    echo "âœ… Terraform ì¸í”„ë¼ ë°°í¬ ì™„ë£Œ"
else
    echo "â­ï¸  Step 6: Terraform ë°°í¬ ê±´ë„ˆë›°ê¸°"
fi

# Step 7: ë°°í¬ í›„ ê²€ì¦ ë° ì •ë³´ ì¶œë ¥
if [[ "$DRY_RUN" != "true" && "$SKIP_DEPLOY" != "true" ]]; then
    echo "ğŸ” Step 7: ë°°í¬ í›„ ê²€ì¦ ì¤‘..."
    cd "$STACK_DIR"
    
    # Terraform ì¶œë ¥ê°’ í™•ì¸
    echo "   ğŸ“Š ë°°í¬ ê²°ê³¼ ì¶œë ¥ê°’:"
    ATLANTIS_URL=$(terraform output -raw atlantis_url 2>/dev/null || echo "N/A")
    ATLANTIS_DNS=$(terraform output -raw atlantis_load_balancer_dns 2>/dev/null || echo "N/A")
    EFS_ID=$(terraform output -raw efs_file_system_id 2>/dev/null || echo "N/A")
    
    echo "   ğŸŒ Atlantis URL: $ATLANTIS_URL"
    echo "   ğŸ“¡ ALB DNS: $ATLANTIS_DNS"
    echo "   ğŸ’¾ EFS File System: $EFS_ID"
    
    # í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸ (ì„ íƒì )
    if [[ "$ATLANTIS_URL" != "N/A" && "$ATLANTIS_URL" != "" ]]; then
        echo "   ğŸ¥ í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸ ì¤‘..."
        sleep 10  # ì„œë¹„ìŠ¤ê°€ ì‹œì‘í•  ì‹œê°„ì„ ì¤Œ
        
        if curl -s -o /dev/null -w "%{http_code}" "$ATLANTIS_URL/healthz" | grep -q "200"; then
            echo "   âœ… Atlantis ì„œë¹„ìŠ¤ ì •ìƒ ë™ì‘ í™•ì¸"
        else
            echo "   âš ï¸  Atlantis ì„œë¹„ìŠ¤ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª‡ ë¶„ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."
        fi
    fi
    
    echo "âœ… ë°°í¬ í›„ ê²€ì¦ ì™„ë£Œ"
fi

echo ""
echo "ğŸ‰ StackKit Atlantis AI Reviewer ì…‹ì—… ì™„ë£Œ!"
echo "=========================================="

if [[ "$DRY_RUN" != "true" && "$SKIP_DEPLOY" != "true" ]]; then
    echo ""
    echo "ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:"
    echo "1. ğŸ”— GitHub Repositoryì— Webhook ì„¤ì •"
    echo "   - Repository Settings â†’ Webhooks â†’ Add webhook"
    echo "   - Payload URL: $ATLANTIS_URL/events"
    echo "   - Content type: application/json"
    echo "   - Secret: (AWS Secrets Managerì—ì„œ atlantis/webhook-secret í™•ì¸)"
    echo "   - Events: Pull requests, Issue comments, Push"
    echo ""
    echo "2. ğŸ“„ Repositoryì— atlantis.yaml íŒŒì¼ ì¶”ê°€"
    echo "   cp $PROJECT_ROOT/atlantis/atlantis.yaml ./atlantis.yaml"
    echo ""
    echo "3. ğŸŒ Atlantis ì›¹ ì¸í„°í˜ì´ìŠ¤ ì ‘ê·¼"
    echo "   ë¸Œë¼ìš°ì €ì—ì„œ $ATLANTIS_URL ì ‘ì†í•˜ì—¬ ë™ì‘ í™•ì¸"
    echo ""
    echo "4. ğŸ§ª í…ŒìŠ¤íŠ¸ PR ìƒì„±í•˜ì—¬ AI ë¦¬ë·° í™•ì¸"
    echo ""
    echo "ğŸ’¡ ìœ ìš©í•œ ëª…ë ¹ì–´:"
    echo "   - Atlantis ë¡œê·¸: aws logs tail /ecs/atlantis-ai-reviewer-atlantis --follow"
    echo "   - Init ì»¨í…Œì´ë„ˆ ë¡œê·¸: aws logs tail /ecs/atlantis-ai-reviewer-atlantis --log-stream-prefix init"
    echo "   - Lambda ë¡œê·¸: aws logs tail /aws/lambda/atlantis-ai-reviewer-plan-ai-reviewer --follow"
    echo "   - CloudWatch ì•ŒëŒ: aws cloudwatch describe-alarms --alarm-names atlantis-ai-reviewer-*"
    echo "   - EFS ìƒíƒœ: aws efs describe-file-systems --file-system-id $EFS_ID"
    echo "   - ì¸í”„ë¼ ì œê±°: cd $STACK_DIR && terraform destroy"
elif [[ "$DRY_RUN" == "true" ]]; then
    echo ""
    echo "ğŸ” DRY RUN ì™„ë£Œ"
    echo "ì‹¤ì œ ë°°í¬ë¥¼ ìœ„í•´ --dry-run ì˜µì…˜ì„ ì œê±°í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”."
    echo ""
    echo "ğŸ“‹ ì˜ˆìƒ ë¦¬ì†ŒìŠ¤:"
    echo "   - ECS í´ëŸ¬ìŠ¤í„° ë° ì„œë¹„ìŠ¤ (Init Container í¬í•¨)"
    echo "   - Application Load Balancer (ê³µìš© ì•¡ì„¸ìŠ¤)"
    echo "   - EFS íŒŒì¼ ì‹œìŠ¤í…œ (BoltDB ì˜ì†ì„±)"
    echo "   - Lambda í•¨ìˆ˜ 2ê°œ (AI ë¦¬ë·°)"
    echo "   - SQS í 2ê°œ + DLQ"
    echo "   - CloudWatch ì•ŒëŒ 4ê°œ"
    echo "   - SNS í† í”½ (ì•Œë¦¼)"
fi

echo ""
echo "ğŸ“š ìì„¸í•œ ë¬¸ì„œ: $PROJECT_ROOT/README.md"
echo "ğŸ› ë¬¸ì œ ë°œìƒ ì‹œ: $PROJECT_ROOT/terraform/docs/TROUBLESHOOTING.md"
