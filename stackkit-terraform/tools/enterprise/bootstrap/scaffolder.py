#!/usr/bin/env python3
"""
StackKit Enterprise Project Scaffolder

Generates complete project structure from templates and configuration
"""

import argparse
import json
import os
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional
import yaml
from datetime import datetime

class ProjectScaffolder:
    """Generates project structure from templates and configuration"""
    
    def __init__(self, output_dir: str):
        self.output_dir = Path(output_dir)
        self.template_engine = TemplateEngine()
        
    def scaffold_project(self, templates: List[Dict], config: Dict[str, Any]) -> None:
        """Generate complete project from templates and configuration"""
        
        # Create base project structure
        self._create_base_structure()
        
        # Generate Terraform configuration
        self._generate_terraform_config(templates, config)
        
        # Generate documentation
        self._generate_documentation(config, templates)
        
        # Generate environment-specific files
        self._generate_environment_files(config)
        
        # Generate CI/CD configuration
        self._generate_cicd_config(config, templates)
        
        # Generate utility scripts
        self._generate_utility_scripts(config)
        
        # Create .gitignore
        self._create_gitignore()
        
        print(f"✅ Project scaffolded successfully at: {self.output_dir}")
    
    def _create_base_structure(self) -> None:
        """Create base project directory structure"""
        directories = [
            "terraform",
            "terraform/environments",
            "terraform/environments/dev",
            "terraform/environments/staging", 
            "terraform/environments/prod",
            "terraform/modules",
            "docs",
            "scripts",
            ".github/workflows",
            "examples"
        ]
        
        for directory in directories:
            (self.output_dir / directory).mkdir(parents=True, exist_ok=True)
    
    def _generate_terraform_config(self, templates: List[Dict], config: Dict[str, Any]) -> None:
        """Generate Terraform configuration files"""
        
        # Main Terraform configuration
        main_tf = self._generate_main_tf(templates, config)
        self._write_file("terraform/main.tf", main_tf)
        
        # Variables
        variables_tf = self._generate_variables_tf(config)
        self._write_file("terraform/variables.tf", variables_tf)
        
        # Outputs
        outputs_tf = self._generate_outputs_tf(templates, config)
        self._write_file("terraform/outputs.tf", outputs_tf)
        
        # Environment-specific tfvars
        for env in ['dev', 'staging', 'prod']:
            tfvars = self._generate_tfvars(config, env)
            self._write_file(f"terraform/environments/{env}/terraform.tfvars", tfvars)
            
            # Environment-specific backend config
            backend_config = self._generate_backend_config(config, env)
            self._write_file(f"terraform/environments/{env}/backend.hcl", backend_config)
    
    def _generate_main_tf(self, templates: List[Dict], config: Dict[str, Any]) -> str:
        """Generate main Terraform configuration"""
        
        template_content = f'''# {config.get('project_name', 'StackKit Project')} - Main Terraform Configuration
# Generated by StackKit Enterprise Bootstrap
# Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

terraform {{
  required_version = ">= 1.5.0"
  
  required_providers {{
    aws = {{
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }}
  }}
  
  # Backend configuration is loaded from backend.hcl
  backend "s3" {{}}
}}

provider "aws" {{
  region = var.aws_region
  
  default_tags {{
    tags = local.common_tags
  }}
}}

# Local values for consistent tagging and naming
locals {{
  common_tags = {{
    Project         = var.project_name
    Environment     = var.environment
    Team            = var.team_name
    Organization    = var.org_name
    ManagedBy       = "terraform"
    CreatedBy       = "stackkit-enterprise"
    Stack           = "${{var.project_name}}-${{var.environment}}"
    CostCenter      = var.cost_center
    Owner           = var.team_name
    LastUpdated     = timestamp()
  }}
  
  # Resource naming
  name_prefix = "${{var.org_name}}-${{var.team_name}}-${{var.environment}}"
  resource_prefix = "${{local.name_prefix}}-${{var.project_name}}"
}}
'''
        
        # Add template-specific modules
        for template in templates:
            template_name = template.get('name', 'unknown')
            
            if template_name == 'base-infrastructure':
                template_content += '''
# Base Infrastructure Module
module "base_infrastructure" {
  source = "./modules/base-infrastructure"
  
  project_name = var.project_name
  environment  = var.environment
  team_name    = var.team_name
  org_name     = var.org_name
  aws_region   = var.aws_region
  
  vpc_cidr                = var.vpc_cidr
  availability_zones      = var.availability_zones
  public_subnet_cidrs     = var.public_subnet_cidrs
  private_subnet_cidrs    = var.private_subnet_cidrs
  
  enable_nat_gateway      = var.enable_nat_gateway
  single_nat_gateway      = var.single_nat_gateway
  enable_vpn_gateway      = var.enable_vpn_gateway
  
  common_tags = local.common_tags
}
'''
            elif template_name in ['nodejs-ecs', 'python-ecs']:
                lang = template_name.split('-')[0]
                template_content += f'''
# {lang.title()} ECS Service Module
module "{lang}_service" {{
  source = "./modules/ecs-service"
  
  project_name = var.project_name
  environment  = var.environment
  service_name = "{lang}-app"
  
  vpc_id             = module.base_infrastructure.vpc_id
  private_subnet_ids = module.base_infrastructure.private_subnet_ids
  public_subnet_ids  = module.base_infrastructure.public_subnet_ids
  
  # Container configuration
  container_image    = var.container_image
  container_port     = var.container_port
  task_cpu          = var.task_cpu
  task_memory       = var.task_memory
  
  # Auto scaling
  min_capacity      = var.min_capacity
  max_capacity      = var.max_capacity
  desired_capacity  = var.desired_capacity
  
  # Health check
  health_check_path = var.health_check_path
  
  common_tags = local.common_tags
  
  depends_on = [module.base_infrastructure]
}}
'''
            elif template_name == 'postgres-rds':
                template_content += '''
# PostgreSQL RDS Module
module "postgres_database" {
  source = "./modules/rds-postgres"
  
  project_name = var.project_name
  environment  = var.environment
  
  vpc_id                = module.base_infrastructure.vpc_id
  private_subnet_ids    = module.base_infrastructure.private_subnet_ids
  
  # Database configuration
  db_name               = var.db_name
  db_username           = var.db_username
  instance_class        = var.db_instance_class
  allocated_storage     = var.db_allocated_storage
  max_allocated_storage = var.db_max_allocated_storage
  
  # Backup configuration
  backup_retention_period = var.backup_retention_period
  backup_window          = var.backup_window
  maintenance_window     = var.maintenance_window
  
  # High availability
  multi_az               = var.multi_az
  
  common_tags = local.common_tags
  
  depends_on = [module.base_infrastructure]
}
'''
        
        # Add compliance modules if needed
        compliance_frameworks = config.get('compliance', [])
        if 'sox' in compliance_frameworks:
            template_content += '''
# SOX Compliance Module
module "sox_compliance" {
  source = "./modules/compliance-sox"
  
  project_name = var.project_name
  environment  = var.environment
  org_name     = var.org_name
  
  common_tags = local.common_tags
}
'''
        
        if 'gdpr' in compliance_frameworks:
            template_content += '''
# GDPR Compliance Module
module "gdpr_compliance" {
  source = "./modules/compliance-gdpr"
  
  project_name = var.project_name
  environment  = var.environment
  org_name     = var.org_name
  
  common_tags = local.common_tags
}
'''
        
        return template_content
    
    def _generate_variables_tf(self, config: Dict[str, Any]) -> str:
        """Generate variables.tf file"""
        
        return f'''# Variables for {config.get('project_name', 'StackKit Project')}
# Generated by StackKit Enterprise Bootstrap

# Project identification
variable "project_name" {{
  description = "Name of the project"
  type        = string
}}

variable "environment" {{
  description = "Environment name"
  type        = string
  validation {{
    condition     = contains(["dev", "staging", "prod"], var.environment)
    error_message = "Environment must be dev, staging, or prod."
  }}
}}

variable "team_name" {{
  description = "Name of the team owning this project"
  type        = string
}}

variable "org_name" {{
  description = "Name of the organization"
  type        = string
}}

# AWS Configuration
variable "aws_region" {{
  description = "AWS region for resources"
  type        = string
  default     = "ap-northeast-2"
}}

# Cost tracking
variable "cost_center" {{
  description = "Cost center for billing"
  type        = string
  default     = "engineering"
}}

# Networking
variable "vpc_cidr" {{
  description = "CIDR block for VPC"
  type        = string
  default     = "10.0.0.0/16"
}}

variable "availability_zones" {{
  description = "Number of availability zones"
  type        = number
  default     = 2
  validation {{
    condition     = var.availability_zones >= 2 && var.availability_zones <= 4
    error_message = "Availability zones must be between 2 and 4."
  }}
}}

variable "public_subnet_cidrs" {{
  description = "CIDR blocks for public subnets"
  type        = list(string)
  default     = ["10.0.1.0/24", "10.0.2.0/24"]
}}

variable "private_subnet_cidrs" {{
  description = "CIDR blocks for private subnets"  
  type        = list(string)
  default     = ["10.0.10.0/24", "10.0.20.0/24"]
}}

variable "enable_nat_gateway" {{
  description = "Enable NAT Gateway for private subnets"
  type        = bool
  default     = true
}}

variable "single_nat_gateway" {{
  description = "Use single NAT Gateway for cost optimization"
  type        = bool
  default     = false
}}

variable "enable_vpn_gateway" {{
  description = "Enable VPN Gateway"
  type        = bool
  default     = false
}}

# Application configuration
variable "container_image" {{
  description = "Docker image for the application"
  type        = string
  default     = "nginx:latest"
}}

variable "container_port" {{
  description = "Port on which the container listens"
  type        = number
  default     = 80
}}

variable "task_cpu" {{
  description = "CPU units for the task (256, 512, 1024, 2048, 4096)"
  type        = string
  default     = "1024"
  validation {{
    condition     = contains(["256", "512", "1024", "2048", "4096"], var.task_cpu)
    error_message = "Task CPU must be one of: 256, 512, 1024, 2048, 4096."
  }}
}}

variable "task_memory" {{
  description = "Memory for the task in MiB"
  type        = string
  default     = "2048"
}}

# Auto scaling
variable "min_capacity" {{
  description = "Minimum number of tasks"
  type        = number
  default     = 1
}}

variable "max_capacity" {{
  description = "Maximum number of tasks"
  type        = number
  default     = 10
}}

variable "desired_capacity" {{
  description = "Desired number of tasks"
  type        = number
  default     = 2
}}

# Health check
variable "health_check_path" {{
  description = "Path for health check"
  type        = string
  default     = "/health"
}}

# Database configuration (if applicable)
variable "db_name" {{
  description = "Name of the database"
  type        = string
  default     = ""
}}

variable "db_username" {{
  description = "Username for the database"
  type        = string
  default     = "admin"
}}

variable "db_instance_class" {{
  description = "RDS instance class"
  type        = string
  default     = "db.t3.micro"
}}

variable "db_allocated_storage" {{
  description = "Initial storage allocation for RDS"
  type        = number
  default     = 20
}}

variable "db_max_allocated_storage" {{
  description = "Maximum storage allocation for RDS"
  type        = number
  default     = 100
}}

variable "backup_retention_period" {{
  description = "Backup retention period in days"
  type        = number
  default     = 7
}}

variable "backup_window" {{
  description = "Backup window"
  type        = string
  default     = "03:00-04:00"
}}

variable "maintenance_window" {{
  description = "Maintenance window"
  type        = string
  default     = "sun:04:00-sun:05:00"
}}

variable "multi_az" {{
  description = "Enable Multi-AZ deployment"
  type        = bool
  default     = false
}}

# Optional: Custom domain
variable "custom_domain" {{
  description = "Custom domain for the application"
  type        = string
  default     = ""
}}

variable "certificate_arn" {{
  description = "ARN of SSL certificate"
  type        = string
  default     = ""
}}'''
    
    def _generate_outputs_tf(self, templates: List[Dict], config: Dict[str, Any]) -> str:
        """Generate outputs.tf file"""
        
        outputs = f'''# Outputs for {config.get('project_name', 'StackKit Project')}
# Generated by StackKit Enterprise Bootstrap

# Base Infrastructure Outputs
output "vpc_id" {{
  description = "ID of the VPC"
  value       = module.base_infrastructure.vpc_id
}}

output "vpc_cidr_block" {{
  description = "CIDR block of the VPC"
  value       = module.base_infrastructure.vpc_cidr_block
}}

output "public_subnet_ids" {{
  description = "IDs of public subnets"
  value       = module.base_infrastructure.public_subnet_ids
}}

output "private_subnet_ids" {{
  description = "IDs of private subnets"
  value       = module.base_infrastructure.private_subnet_ids
}}
'''
        
        # Add template-specific outputs
        has_ecs = any(t.get('name', '').endswith('-ecs') for t in templates)
        if has_ecs:
            outputs += '''
# Application Outputs
output "application_url" {
  description = "URL of the application"
  value       = module.nodejs_service.application_url
}

output "load_balancer_dns" {
  description = "DNS name of the load balancer"
  value       = module.nodejs_service.load_balancer_dns
}

output "ecs_cluster_name" {
  description = "Name of the ECS cluster"
  value       = module.nodejs_service.cluster_name
}

output "ecs_service_name" {
  description = "Name of the ECS service"
  value       = module.nodejs_service.service_name
}
'''
        
        has_database = any('postgres' in t.get('name', '') or 'mysql' in t.get('name', '') for t in templates)
        if has_database:
            outputs += '''
# Database Outputs
output "database_endpoint" {
  description = "Database endpoint"
  value       = module.postgres_database.endpoint
  sensitive   = true
}

output "database_port" {
  description = "Database port"
  value       = module.postgres_database.port
}
'''
        
        # Add setup instructions
        outputs += f'''
# Setup Instructions
output "setup_instructions" {{
  description = "Next steps after deployment"
  value = <<-EOT
    🎉 {config.get('project_name', 'Project')} deployed successfully!
    
    📋 Next Steps:
    1. Verify deployment: terraform output application_url
    2. Set up monitoring: Check CloudWatch dashboards
    3. Configure DNS: Update Route53 records if using custom domain
    4. Set up CI/CD: Configure GitHub Actions or similar
    
    📚 Documentation:
    - Project README: ../README.md
    - Architecture docs: ../docs/
    
    🔧 Management:
    - AWS Console: https://console.aws.amazon.com/
    - Terraform state: S3 bucket with versioning
    
    ⚠️  Important:
    - Database credentials are stored in AWS Secrets Manager
    - Monitor costs and set up billing alerts
    - Review security groups and access controls
  EOT
}}
'''
        
        return outputs
    
    def _generate_tfvars(self, config: Dict[str, Any], environment: str) -> str:
        """Generate environment-specific terraform.tfvars"""
        
        # Get environment-specific values
        env_config = config.get(environment, {})
        
        tfvars = f'''# Environment-specific configuration for {environment}
# {config.get('project_name', 'StackKit Project')}

# Project identification
project_name = "{config.get('project_name', 'my-project')}"
environment  = "{environment}"
team_name    = "{config.get('team', 'default-team')}"
org_name     = "{config.get('org', 'default-org')}"

# AWS Configuration
aws_region = "{config.get('aws_region', 'ap-northeast-2')}"

# Cost tracking
cost_center = "{config.get('cost_center', 'engineering')}"

# Networking (environment-specific)'''
        
        # Environment-specific networking
        vpc_cidrs = {
            'dev': '10.0.0.0/16',
            'staging': '10.1.0.0/16',
            'prod': '10.2.0.0/16'
        }
        
        tfvars += f'''
vpc_cidr = "{vpc_cidrs.get(environment, '10.0.0.0/16')}"
'''
        
        # Environment-specific sizing
        if environment == 'dev':
            tfvars += '''
# Development environment - cost optimized
single_nat_gateway = true
enable_vpn_gateway = false

# Application sizing
task_cpu    = "512"
task_memory = "1024"

min_capacity     = 1
max_capacity     = 3
desired_capacity = 1

# Database sizing
db_instance_class        = "db.t3.micro"
db_allocated_storage     = 20
db_max_allocated_storage = 50
multi_az                = false
backup_retention_period = 7'''
        
        elif environment == 'staging':
            tfvars += '''
# Staging environment - balanced
single_nat_gateway = false
enable_vpn_gateway = false

# Application sizing
task_cpu    = "1024"
task_memory = "2048"

min_capacity     = 2
max_capacity     = 6
desired_capacity = 2

# Database sizing
db_instance_class        = "db.t3.small"
db_allocated_storage     = 50
db_max_allocated_storage = 100
multi_az                = false
backup_retention_period = 14'''
        
        elif environment == 'prod':
            tfvars += '''
# Production environment - high availability
single_nat_gateway = false
enable_vpn_gateway = false

# Application sizing
task_cpu    = "2048"
task_memory = "4096"

min_capacity     = 3
max_capacity     = 20
desired_capacity = 5

# Database sizing
db_instance_class        = "db.r5.large"
db_allocated_storage     = 100
db_max_allocated_storage = 500
multi_az                = true
backup_retention_period = 30'''
        
        return tfvars
    
    def _generate_backend_config(self, config: Dict[str, Any], environment: str) -> str:
        """Generate backend configuration for Terraform state"""
        
        org = config.get('org', 'default-org')
        project = config.get('project_name', 'my-project')
        
        return f'''# Terraform backend configuration for {environment}
# Store state in S3 with DynamoDB locking

bucket         = "{org}-terraform-state"
key            = "{project}/{environment}/terraform.tfstate"
region         = "{config.get('aws_region', 'ap-northeast-2')}"
dynamodb_table = "{org}-terraform-locks"
encrypt        = true

# Optional: Use workspace isolation
# workspace_key_prefix = "{project}"'''
    
    def _generate_documentation(self, config: Dict[str, Any], templates: List[Dict]) -> None:
        """Generate project documentation"""
        
        # Main README
        readme = self._generate_readme(config, templates)
        self._write_file("README.md", readme)
        
        # Architecture documentation
        architecture_doc = self._generate_architecture_doc(config, templates)
        self._write_file("docs/architecture.md", architecture_doc)
        
        # Deployment guide
        deployment_doc = self._generate_deployment_doc(config)
        self._write_file("docs/deployment.md", deployment_doc)
    
    def _generate_readme(self, config: Dict[str, Any], templates: List[Dict]) -> str:
        """Generate main README.md"""
        
        project_name = config.get('project_name', 'StackKit Project')
        team = config.get('team', 'Development Team')
        org = config.get('org', 'Organization')
        
        readme = f'''# {project_name}

**{team}** project infrastructure managed by StackKit Enterprise

---

## 🏗️ Architecture Overview

This project was generated using StackKit Enterprise Bootstrap with the following templates:

'''
        
        for template in templates:
            readme += f"- **{template.get('name', 'Unknown')}**: {template.get('description', 'No description')}\n"
        
        readme += f'''

## 🚀 Quick Start

### Prerequisites

- AWS CLI configured with appropriate permissions
- Terraform >= 1.5.0 installed
- Access to {org} AWS accounts

### Deployment

```bash
# 1. Clone and navigate to project
git clone <repository-url>
cd {project_name.lower().replace(' ', '-')}

# 2. Choose environment
cd terraform/environments/dev  # or staging/prod

# 3. Initialize Terraform
terraform init -backend-config=backend.hcl

# 4. Review and apply
terraform plan
terraform apply
```

### Environment-Specific Deployment

#### Development
```bash
cd terraform/environments/dev
terraform init -backend-config=backend.hcl
terraform apply
```

#### Staging  
```bash
cd terraform/environments/staging
terraform init -backend-config=backend.hcl
terraform apply
```

#### Production
```bash
cd terraform/environments/prod
terraform init -backend-config=backend.hcl
terraform apply
```

## 📁 Project Structure

```
{project_name.lower().replace(' ', '-')}/
├── terraform/
│   ├── main.tf              # Main Terraform configuration
│   ├── variables.tf         # Variable definitions
│   ├── outputs.tf           # Output definitions
│   ├── modules/             # Custom modules
│   └── environments/        # Environment-specific configs
│       ├── dev/
│       ├── staging/
│       └── prod/
├── docs/                    # Documentation
│   ├── architecture.md     # Architecture overview
│   └── deployment.md       # Deployment guide
├── scripts/                 # Utility scripts
├── .github/workflows/       # CI/CD workflows
└── README.md               # This file
```

## 🔧 Configuration

Configuration follows the StackKit Enterprise hierarchy:

1. **Organization** → Base policies and standards
2. **Team** → Team-specific configurations  
3. **Environment** → Environment-specific settings
4. **Project** → Project-specific overrides

### Key Configuration Files

- `terraform/environments/*/terraform.tfvars` - Environment variables
- `terraform/environments/*/backend.hcl` - Backend configuration

## 🛡️ Security & Compliance

'''
        
        compliance = config.get('compliance', [])
        if compliance:
            readme += f"This project implements the following compliance frameworks:\n"
            for framework in compliance:
                readme += f"- **{framework.upper()}** compliance\n"
        else:
            readme += "Standard security practices are implemented according to organization policies.\n"
        
        readme += '''
### Security Features

- Encrypted storage and transit
- VPC isolation with private subnets
- Security groups with least-privilege access
- AWS Secrets Manager for credential management
- CloudTrail logging and monitoring

## 📊 Monitoring & Observability

- **CloudWatch** - Metrics, logs, and dashboards
- **CloudTrail** - API call auditing
- **Config** - Configuration compliance monitoring
- **Health Checks** - Application and infrastructure health

## 🚨 Alerting

Alerts are configured for:

- High CPU/memory utilization
- Application errors
- Infrastructure failures
- Security events
- Cost thresholds

## 💰 Cost Management

- **Environment-specific sizing** - Right-sized resources per environment
- **Auto-scaling** - Dynamic scaling based on demand
- **Cost allocation tags** - Detailed cost tracking
- **Budget alerts** - Proactive cost monitoring

## 🔄 CI/CD Integration

GitHub Actions workflows are configured for:

- **Terraform validation** - Syntax and security checks
- **Automated testing** - Infrastructure tests
- **Deployment** - Environment-specific deployments
- **Security scanning** - Vulnerability assessments

## 📞 Support & Documentation

### Team Contacts

- **Team**: {team}
- **Organization**: {org}
- **Primary Contact**: [Team Lead Email]
- **Slack Channel**: #{team.lower().replace(' ', '-')}

### Additional Documentation

- [Architecture Documentation](docs/architecture.md)
- [Deployment Guide](docs/deployment.md)
- [StackKit Documentation](https://github.com/your-org/stackkit)

### Getting Help

1. Check the documentation in the `docs/` directory
2. Search existing issues in the repository
3. Contact the team via Slack
4. Create an issue with detailed information

---

**Generated by StackKit Enterprise Bootstrap** | **Last Updated**: {datetime.now().strftime('%Y-%m-%d')}
'''
        
        return readme
    
    def _generate_architecture_doc(self, config: Dict[str, Any], templates: List[Dict]) -> str:
        """Generate architecture documentation"""
        
        doc = f'''# Architecture Documentation

## System Overview

{config.get('project_name', 'This project')} is built using StackKit Enterprise templates with the following architecture patterns:

### Templates Used

'''
        
        for template in templates:
            doc += f"#### {template.get('name', 'Unknown Template')}\n"
            doc += f"- **Type**: {template.get('type', 'Unknown')}\n"
            doc += f"- **Description**: {template.get('description', 'No description')}\n"
            if template.get('categories'):
                doc += f"- **Categories**: {', '.join(template.get('categories', []))}\n"
            doc += "\n"
        
        doc += '''### Infrastructure Components

#### Networking
- **VPC**: Isolated network environment
- **Subnets**: Public and private subnets across multiple AZs
- **NAT Gateway**: Outbound internet access for private resources
- **Security Groups**: Fine-grained access control

#### Compute
- **ECS Fargate**: Serverless container orchestration
- **Application Load Balancer**: HTTP/HTTPS traffic distribution
- **Auto Scaling**: Dynamic capacity management

#### Storage & Database
- **RDS**: Managed relational database
- **S3**: Object storage for static assets
- **Secrets Manager**: Secure credential storage

#### Monitoring & Security
- **CloudWatch**: Metrics, logs, and monitoring
- **CloudTrail**: API audit logging
- **WAF**: Web application firewall protection
- **KMS**: Encryption key management

### Architecture Decisions

#### Why ECS Fargate?
- Serverless container management
- No EC2 instance management overhead
- Built-in security and compliance features
- Pay-per-use pricing model

#### Why RDS over self-managed database?
- Automated backups and maintenance
- High availability with Multi-AZ
- Built-in monitoring and alerting
- Managed security patches

#### Why Application Load Balancer?
- Layer 7 routing capabilities
- SSL/TLS termination
- Health check integration
- Integration with AWS services

### Security Architecture

#### Network Security
- Private subnets for application and database tiers
- Security groups with minimal required access
- NACLs for additional network-level protection

#### Data Security
- Encryption at rest using KMS
- Encryption in transit using TLS
- Secure credential management with Secrets Manager

#### Access Control
- IAM roles and policies with least privilege
- Resource-based policies where applicable
- Cross-service access via IAM roles

### Scalability Considerations

#### Horizontal Scaling
- ECS service auto-scaling based on CPU/memory
- Application Load Balancer distributes traffic
- Read replicas for database scaling

#### Vertical Scaling
- ECS task sizing can be adjusted
- RDS instance class can be upgraded
- Storage auto-scaling enabled

### Disaster Recovery

#### Backup Strategy
- Automated RDS backups with point-in-time recovery
- S3 cross-region replication for critical data
- Configuration stored in version control

#### Recovery Procedures
- Infrastructure as Code for rapid rebuild
- Database restore from automated backups
- Application deployment via CI/CD pipeline

### Cost Optimization

#### Resource Optimization
- Right-sizing based on actual usage
- Spot instances for non-critical workloads
- Reserved instances for predictable workloads

#### Monitoring & Alerting
- Cost allocation tags for detailed tracking
- Budget alerts for cost control
- Resource utilization monitoring

---

*Last Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
'''
        
        return doc
    
    def _generate_deployment_doc(self, config: Dict[str, Any]) -> str:
        """Generate deployment documentation"""
        
        return f'''# Deployment Guide

## Prerequisites

### Tools Required
- **Terraform** >= 1.5.0
- **AWS CLI** >= 2.0.0
- **Git** for version control

### AWS Permissions Required
- EC2, ECS, RDS full access
- S3, Secrets Manager, KMS access
- IAM role creation and management
- VPC and networking management

### Initial Setup

#### 1. AWS Configuration
```bash
aws configure
# Enter your access key, secret key, region, and output format
```

#### 2. Terraform Backend Setup
```bash
# Create S3 bucket for Terraform state (one-time setup)
aws s3 mb s3://{config.get('org', 'your-org')}-terraform-state

# Create DynamoDB table for state locking
aws dynamodb create-table \\
    --table-name {config.get('org', 'your-org')}-terraform-locks \\
    --attribute-definitions AttributeName=LockID,AttributeType=S \\
    --key-schema AttributeName=LockID,KeyType=HASH \\
    --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5
```

## Environment Deployment

### Development Environment

```bash
# Navigate to dev environment
cd terraform/environments/dev

# Initialize Terraform
terraform init -backend-config=backend.hcl

# Review the plan
terraform plan

# Apply changes
terraform apply

# Get outputs
terraform output
```

### Staging Environment

```bash
# Navigate to staging environment
cd terraform/environments/staging

# Initialize Terraform
terraform init -backend-config=backend.hcl

# Review the plan
terraform plan

# Apply changes
terraform apply
```

### Production Environment

```bash
# Navigate to production environment
cd terraform/environments/prod

# Initialize Terraform
terraform init -backend-config=backend.hcl

# Review the plan carefully
terraform plan

# Apply changes (consider using -auto-approve=false)
terraform apply

# Verify deployment
terraform output setup_instructions
```

## Configuration Management

### Environment-Specific Variables

Each environment has its own `terraform.tfvars` file:

- `environments/dev/terraform.tfvars` - Development settings
- `environments/staging/terraform.tfvars` - Staging settings  
- `environments/prod/terraform.tfvars` - Production settings

### Variable Customization

Key variables you may want to customize:

```hcl
# Application sizing
task_cpu    = "1024"  # CPU units
task_memory = "2048"  # Memory in MiB

# Auto scaling
min_capacity     = 2
max_capacity     = 10
desired_capacity = 3

# Database sizing
db_instance_class = "db.t3.small"
multi_az         = true  # for production

# Custom domain (optional)
custom_domain    = "myapp.example.com"
certificate_arn  = "arn:aws:acm:region:account:certificate/xxx"
```

## Validation & Testing

### Pre-Deployment Checks

```bash
# Validate Terraform configuration
terraform validate

# Format Terraform files
terraform fmt -recursive

# Security scanning (if tfsec is installed)
tfsec .

# Cost estimation (if infracost is installed)
infracost breakdown --path .
```

### Post-Deployment Verification

```bash
# Check resource creation
terraform show

# Verify outputs
terraform output

# Test application endpoint
curl $(terraform output -raw application_url)/health

# Check database connectivity (if applicable)
# This requires appropriate network access
```

## Troubleshooting

### Common Issues

#### Backend Configuration Errors
```bash
# If backend initialization fails
terraform init -reconfigure -backend-config=backend.hcl
```

#### Resource Limit Errors
Check AWS service limits and request increases if needed:
- VPC limits
- ECS service limits
- RDS instance limits

#### Permission Errors
Ensure IAM user/role has required permissions:
```bash
# Check current identity
aws sts get-caller-identity

# Verify permissions
aws iam get-user
```

### Debugging Commands

```bash
# Enable debug logging
export TF_LOG=DEBUG
terraform apply

# Check AWS resource status
aws ecs describe-clusters --clusters <cluster-name>
aws rds describe-db-instances --db-instance-identifier <instance-id>
```

## Maintenance

### Regular Updates

#### Monthly
- Review AWS service updates
- Update Terraform provider versions
- Review cost reports and optimize

#### Quarterly  
- Review security groups and access
- Update AMIs and base images
- Perform disaster recovery tests

### Backup Verification

```bash
# Check RDS backup status
aws rds describe-db-snapshots --db-instance-identifier <instance-id>

# Verify S3 versioning
aws s3api get-bucket-versioning --bucket <bucket-name>
```

### State Management

```bash
# Backup Terraform state
terraform state pull > backup.tfstate

# List state resources
terraform state list

# Import existing resources (if needed)
terraform import aws_instance.example i-1234567890abcdef0
```

## Rollback Procedures

### Application Rollback
```bash
# Revert to previous task definition
aws ecs update-service --cluster <cluster> --service <service> \\
    --task-definition <previous-task-def>
```

### Infrastructure Rollback
```bash
# Use Terraform to revert to previous configuration
git checkout <previous-commit>
terraform plan
terraform apply
```

### Database Rollback
```bash
# Restore from snapshot (creates new instance)
aws rds restore-db-instance-from-db-snapshot \\
    --db-instance-identifier <new-id> \\
    --db-snapshot-identifier <snapshot-id>
```

---

*Generated by StackKit Enterprise Bootstrap*
*Last Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
'''
    
    def _generate_environment_files(self, config: Dict[str, Any]) -> None:
        """Generate environment-specific files"""
        pass  # Already handled in Terraform generation
    
    def _generate_cicd_config(self, config: Dict[str, Any], templates: List[Dict]) -> None:
        """Generate CI/CD workflow configuration"""
        
        github_workflow = f'''name: Infrastructure Deployment

on:
  push:
    branches: [ main, develop ]
    paths: 
      - 'terraform/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'terraform/**'

env:
  AWS_REGION: {config.get('aws_region', 'ap-northeast-2')}
  TF_VERSION: '1.5.0'

jobs:
  validate:
    name: Validate Terraform
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: ${{{{ env.TF_VERSION }}}}
    
    - name: Terraform Format Check
      run: terraform fmt -check -recursive
      
    - name: Terraform Init
      run: terraform init -backend=false
      working-directory: ./terraform
      
    - name: Terraform Validate
      run: terraform validate
      working-directory: ./terraform
    
    - name: Security Scan
      uses: aquasecurity/tfsec-action@v1.0.3
      with:
        working_directory: ./terraform

  plan-dev:
    name: Plan Development
    runs-on: ubuntu-latest
    needs: validate
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{{{ secrets.AWS_ACCESS_KEY_ID_DEV }}}}
        aws-secret-access-key: ${{{{ secrets.AWS_SECRET_ACCESS_KEY_DEV }}}}
        aws-region: ${{{{ env.AWS_REGION }}}}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: ${{{{ env.TF_VERSION }}}}
    
    - name: Terraform Init
      run: terraform init -backend-config=backend.hcl
      working-directory: ./terraform/environments/dev
    
    - name: Terraform Plan
      run: terraform plan -no-color
      working-directory: ./terraform/environments/dev
      
  deploy-dev:
    name: Deploy to Development
    runs-on: ubuntu-latest
    needs: validate
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    environment: development
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{{{ secrets.AWS_ACCESS_KEY_ID_DEV }}}}
        aws-secret-access-key: ${{{{ secrets.AWS_SECRET_ACCESS_KEY_DEV }}}}
        aws-region: ${{{{ env.AWS_REGION }}}}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: ${{{{ env.TF_VERSION }}}}
    
    - name: Terraform Init
      run: terraform init -backend-config=backend.hcl
      working-directory: ./terraform/environments/dev
    
    - name: Terraform Apply
      run: terraform apply -auto-approve
      working-directory: ./terraform/environments/dev

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: validate
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: staging
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{{{ secrets.AWS_ACCESS_KEY_ID_STAGING }}}}
        aws-secret-access-key: ${{{{ secrets.AWS_SECRET_ACCESS_KEY_STAGING }}}}
        aws-region: ${{{{ env.AWS_REGION }}}}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: ${{{{ env.TF_VERSION }}}}
    
    - name: Terraform Init
      run: terraform init -backend-config=backend.hcl
      working-directory: ./terraform/environments/staging
    
    - name: Terraform Plan
      run: terraform plan
      working-directory: ./terraform/environments/staging
    
    - name: Terraform Apply
      run: terraform apply -auto-approve
      working-directory: ./terraform/environments/staging

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: deploy-staging
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{{{ secrets.AWS_ACCESS_KEY_ID_PROD }}}}
        aws-secret-access-key: ${{{{ secrets.AWS_SECRET_ACCESS_KEY_PROD }}}}
        aws-region: ${{{{ env.AWS_REGION }}}}
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: ${{{{ env.TF_VERSION }}}}
    
    - name: Terraform Init
      run: terraform init -backend-config=backend.hcl
      working-directory: ./terraform/environments/prod
    
    - name: Terraform Plan
      run: terraform plan
      working-directory: ./terraform/environments/prod
    
    - name: Manual Approval
      uses: trstringer/manual-approval@v1
      with:
        secret: ${{{{ github.TOKEN }}}}
        approvers: team-leads,devops-team
        minimum-approvals: 2
        issue-title: "Production Deployment Approval Required"
    
    - name: Terraform Apply
      run: terraform apply -auto-approve
      working-directory: ./terraform/environments/prod
'''
        
        self._write_file(".github/workflows/infrastructure.yml", github_workflow)
    
    def _generate_utility_scripts(self, config: Dict[str, Any]) -> None:
        """Generate utility scripts"""
        
        # Deployment script
        deploy_script = f'''#!/bin/bash
set -euo pipefail

# {config.get('project_name', 'Project')} Deployment Script
# Generated by StackKit Enterprise Bootstrap

SCRIPT_DIR="$(cd "$(dirname "${{BASH_SOURCE[0]}}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

# Colors
RED='\\033[0;31m'
GREEN='\\033[0;32m'
YELLOW='\\033[1;33m'
BLUE='\\033[0;34m'
NC='\\033[0m'

log() {{ echo -e "${{BLUE}}ℹ️  $*${{NC}}"; }}
ok() {{ echo -e "${{GREEN}}✅ $*${{NC}}"; }}
warn() {{ echo -e "${{YELLOW}}⚠️  $*${{NC}}"; }}
fail() {{ echo -e "${{RED}}❌ $*${{NC}}"; exit 1; }}

usage() {{
    cat <<EOF
Usage: $(basename "$0") [ENVIRONMENT] [OPTIONS]

Deploy {config.get('project_name', 'project')} infrastructure to specified environment.

ENVIRONMENTS:
    dev         Deploy to development environment
    staging     Deploy to staging environment  
    prod        Deploy to production environment

OPTIONS:
    --plan-only     Only run terraform plan
    --auto-approve  Skip interactive approval
    --destroy       Destroy infrastructure
    --help          Show this help message

EXAMPLES:
    $(basename "$0") dev                    # Deploy to dev with confirmation
    $(basename "$0") prod --plan-only       # Plan production deployment
    $(basename "$0") staging --auto-approve # Deploy staging without confirmation

PREREQUISITES:
    - AWS CLI configured with appropriate credentials
    - Terraform >= 1.5.0 installed
    - Access to {config.get('org', 'organization')} AWS accounts
EOF
}}

deploy_environment() {{
    local env="$1"
    local plan_only="${{2:-false}}"
    local auto_approve="${{3:-false}}"
    local destroy="${{4:-false}}"
    
    local terraform_dir="$PROJECT_ROOT/terraform/environments/$env"
    
    if [[ ! -d "$terraform_dir" ]]; then
        fail "Environment directory not found: $terraform_dir"
    fi
    
    log "Deploying to $env environment"
    cd "$terraform_dir"
    
    # Check if backend is configured
    if [[ ! -f "backend.hcl" ]]; then
        fail "Backend configuration not found: backend.hcl"
    fi
    
    # Initialize Terraform
    log "Initializing Terraform..."
    terraform init -backend-config=backend.hcl
    
    # Validate configuration
    log "Validating configuration..."
    terraform validate
    
    if [[ "$destroy" == "true" ]]; then
        warn "DESTRUCTIVE OPERATION: This will destroy all resources in $env"
        if [[ "$auto_approve" != "true" ]]; then
            read -p "Are you sure you want to destroy $env environment? (yes/no): " confirm
            if [[ "$confirm" != "yes" ]]; then
                log "Destruction cancelled"
                return 0
            fi
        fi
        
        terraform destroy $([[ "$auto_approve" == "true" ]] && echo "-auto-approve")
        return 0
    fi
    
    # Run terraform plan
    log "Planning deployment..."
    terraform plan -out=tfplan
    
    if [[ "$plan_only" == "true" ]]; then
        ok "Plan completed successfully"
        return 0
    fi
    
    # Apply changes
    if [[ "$auto_approve" != "true" ]]; then
        warn "About to apply changes to $env environment"
        read -p "Proceed with deployment? (yes/no): " confirm
        if [[ "$confirm" != "yes" ]]; then
            log "Deployment cancelled"
            return 0
        fi
    fi
    
    log "Applying changes..."
    terraform apply tfplan
    
    # Show outputs
    ok "Deployment completed successfully!"
    echo
    log "Deployment summary:"
    terraform output setup_instructions
}}

# Parse command line arguments
ENVIRONMENT=""
PLAN_ONLY=false
AUTO_APPROVE=false
DESTROY=false

while [[ $# -gt 0 ]]; do
    case $1 in
        dev|staging|prod)
            ENVIRONMENT="$1"
            shift
            ;;
        --plan-only)
            PLAN_ONLY=true
            shift
            ;;
        --auto-approve)
            AUTO_APPROVE=true
            shift
            ;;
        --destroy)
            DESTROY=true
            shift
            ;;
        --help|-h)
            usage
            exit 0
            ;;
        *)
            fail "Unknown option: $1"
            ;;
    esac
done

# Validate environment
if [[ -z "$ENVIRONMENT" ]]; then
    fail "Environment is required. Use --help for usage information."
fi

if [[ ! "$ENVIRONMENT" =~ ^(dev|staging|prod)$ ]]; then
    fail "Invalid environment: $ENVIRONMENT. Must be dev, staging, or prod."
fi

# Check prerequisites
command -v terraform >/dev/null 2>&1 || fail "Terraform is not installed"
command -v aws >/dev/null 2>&1 || fail "AWS CLI is not installed"

# Verify AWS credentials
aws sts get-caller-identity >/dev/null 2>&1 || fail "AWS credentials not configured"

# Deploy
deploy_environment "$ENVIRONMENT" "$PLAN_ONLY" "$AUTO_APPROVE" "$DESTROY"
'''
        
        self._write_file("scripts/deploy.sh", deploy_script, executable=True)
        
        # Cost estimation script
        cost_script = '''#!/bin/bash
set -euo pipefail

# Cost estimation script using infracost
# Requires infracost to be installed and configured

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

# Colors  
BLUE='\\033[0;34m'
GREEN='\\033[0;32m'
NC='\\033[0m'

log() { echo -e "${BLUE}ℹ️  $*${NC}"; }
ok() { echo -e "${GREEN}✅ $*${NC}"; }

usage() {
    cat <<EOF
Usage: $(basename "$0") [ENVIRONMENT]

Generate cost estimation for infrastructure.

ENVIRONMENTS:
    dev         Estimate development environment costs
    staging     Estimate staging environment costs  
    prod        Estimate production environment costs
    all         Estimate all environments

EXAMPLES:
    $(basename "$0") dev        # Estimate dev environment
    $(basename "$0") all        # Estimate all environments
EOF
}

estimate_environment() {
    local env="$1"
    local terraform_dir="$PROJECT_ROOT/terraform/environments/$env"
    
    if [[ ! -d "$terraform_dir" ]]; then
        echo "Environment directory not found: $terraform_dir"
        return 1
    fi
    
    log "Estimating costs for $env environment"
    cd "$terraform_dir"
    
    # Check if infracost is available
    if ! command -v infracost >/dev/null 2>&1; then
        echo "⚠️  Infracost not installed. Install from: https://www.infracost.io/docs/"
        return 1
    fi
    
    # Generate cost breakdown
    infracost breakdown --path . --format table
    echo
}

ENVIRONMENT="${1:-}"

case "$ENVIRONMENT" in
    dev|staging|prod)
        estimate_environment "$ENVIRONMENT"
        ;;
    all)
        for env in dev staging prod; do
            estimate_environment "$env"
            echo "----------------------------------------"
        done
        ;;
    --help|-h|"")
        usage
        exit 0
        ;;
    *)
        echo "Invalid environment: $ENVIRONMENT"
        usage
        exit 1
        ;;
esac
'''
        
        self._write_file("scripts/estimate-costs.sh", cost_script, executable=True)
    
    def _create_gitignore(self) -> None:
        """Create .gitignore file"""
        
        gitignore = '''# Terraform
*.tfstate
*.tfstate.*
*.tfvars
!*.tfvars.example
.terraform/
.terraform.lock.hcl
tfplan
crash.log

# Local environment files
.env
.env.local
.env.*.local

# IDE files
.vscode/
.idea/
*.swp
*.swo

# OS files
.DS_Store
Thumbs.db

# Logs
logs/
*.log

# Temporary files
tmp/
temp/
*.tmp

# Backup files
*.backup
*.bak
*~

# Application specific
node_modules/
dist/
build/

# Secrets and keys
*.pem
*.key
*.p12
*.crt
secrets/
'''
        
        self._write_file(".gitignore", gitignore)
    
    def _write_file(self, relative_path: str, content: str, executable: bool = False) -> None:
        """Write content to file with proper permissions"""
        
        file_path = self.output_dir / relative_path
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w') as f:
            f.write(content)
        
        if executable:
            os.chmod(file_path, 0o755)

class TemplateEngine:
    """Simple template engine for variable substitution"""
    
    def render(self, template: str, context: Dict[str, Any]) -> str:
        """Render template with context variables"""
        
        # Simple variable substitution
        import re
        
        def replace_var(match):
            var_name = match.group(1)
            return str(context.get(var_name, match.group(0)))
        
        return re.sub(r'\\{\\{([^}]+)\\}\\}', replace_var, template)

def main():
    parser = argparse.ArgumentParser(description="StackKit Enterprise Project Scaffolder")
    parser.add_argument("--output-dir", required=True, help="Project output directory")
    parser.add_argument("--templates", required=True, help="Selected templates JSON")
    parser.add_argument("--config", required=True, help="Merged configuration JSON")
    
    args = parser.parse_args()
    
    # Parse inputs
    try:
        templates = json.loads(args.templates)
        config = json.loads(args.config)
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON input: {e}")
        return 1
    
    # Scaffold project
    scaffolder = ProjectScaffolder(args.output_dir)
    scaffolder.scaffold_project(templates, config)
    
    return 0

if __name__ == "__main__":
    exit(main())